{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AM 207**: Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verena Kaynig-Fittkau and Pavlos Protopapas  <br>\n",
    "**Due: 11.59 P.M. Thursday April 14th, 2016**\n",
    "\n",
    "### Note: This homework is only for one week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "+ Upload your answers in an ipython notebook to Canvas.\n",
    "\n",
    "+ We will provide you imports for your ipython notebook. Please do not import additional libraries.\n",
    "\n",
    "+ Your individual submissions should use the following filenames: AM207_YOURNAME_HW5.ipynb\n",
    "\n",
    "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format). \n",
    "\n",
    "+ **Do not just send your code. The homework solutions should be in a report style. Be sure to add comments to your code as well as markdown cells where you describe your approach and discuss your results. **\n",
    "\n",
    "+ Please submit your notebook in an executed status, so that we can see all the results you computed. However, we will still run your code and all cells should reproduce the output when executed. \n",
    "\n",
    "+ If you have multiple files (e.g. you've added code files or images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HW5.tar.gz or AM207_YOURNAME_HW5.zip\n",
    "\n",
    "\n",
    "### Have Fun!\n",
    "_ _ _ _ _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: HMM... I Think Your Text Got Corrupted!\n",
    "\n",
    "In this problem you should use a Hidden Markov Model to correct typos in a text without using a dictionary. Your data is in two different text files:\n",
    "\n",
    "* `Shakespeare_correct.txt` contains the words of some sonnets from Shakespeare\n",
    "* `Shakespeare_typos.txt` contains the same text, but now some of the characters are corrupted\n",
    "\n",
    "For convenience both text files only contain lower case letters a-z and spaces. \n",
    "\n",
    "First build a first order HMM:\n",
    "* What are the hidden states and what are the observed states?\n",
    "* What should you do to generate your HMM probability matrices?\n",
    "* For some of the HMM parameters, you won't have enough training data to get representative probabilities.  For example, some of your probabilites might be 0. You should address this problem by adding a small pseudocount, similar to the motif finding problem from a previous assignment. \n",
    "* Implement the Viterbi algorithm and run it on a test portion that contains errors. Show that your Viterbi implementation can improve text of length 100, 500, 1000, and 2000. Note: To do this correctly you would have to withhold the part of the text that you use for testing when you estimate the parameters for you HMM. For the sake of this homework it is ok though to report training error instead of test error. Just be aware that the correction rate you are reporting most likely is a very optimistic estimate. \n",
    "* What correction rate do you get?\n",
    "\n",
    "**Important**: Wikipedia has a nice article on [Viterbi](https://en.wikipedia.org/wiki/Viterbi_algorithm). **Please do not use the python implementation from this article!** (The lecture notebook also has the version from Wikipedia). Using dictionaries for Viterbi is really not intuitive and using numpy is typically faster. The article has very nice pseudo code that should enable you to easily program Viterbi by yourself. Please also refrain for this problem from using any other third party implementations. \n",
    "\n",
    "Now for a second order HMM:\n",
    "By using a second order HMM, you should be able to get a better correction rate. \n",
    "* Give an intuitive explanation why a second order HMM should give better results.\n",
    "* Implement your second order text correction. Hint: If you think a bit about the model you won't even have to change your Viterbi implementation. \n",
    "* Compare your correction rates against the first order model for text length of 100 and 500, (you can do 1000 as well if your computer is fast enough). \n",
    "* How well would your implementation scale to HMMs of even higher order? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: First Order HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the hidden states and what are the observed states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our hidden states are the correct characters at position t.\n",
    "* Our observed states are the characters at position t in the document with typos.\n",
    "\n",
    "In this problem, we have 27 hidden states (a,b,c,...,z and space) and 27 observed states (a,b,c,...,z and space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = open(\"Shakespeare_correct.txt\").read()\n",
    "typo = open(\"Shakespeare_typos.txt\").read()\n",
    "states_set = string.ascii_lowercase + \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What should you do to generate your HMM probability matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HMM model, we need a transition matrix, a emission matrix and a initial state vector.\n",
    "\n",
    "Trainsion Matrix *T*: it contains the transition probabilities between hidden states and hidden states. In this problem, it is a $27^2 * 27^2$ matrix. Our row and column are both the 27 hidden states and Entry $e_{ij}$ represents the probability to transit from hidden state i to j. We could use our correct document to train the transition matrix. For each $e_{ij}$, we first calculate the appearance times of ith hidden state is at position t while jth hidden state is at position t+1 in the whole correct document. And then we could normalize the matrix so that the sum of each row to be one.\n",
    "\n",
    "Emission Matrix *E*: each entry $e_{ij}$ is the probability of observed state j at position t given hidden state i at position t. As with T, the matrix E is row stochastic. In our problem, since we have 27 hidden states as well as 27 observed states, it should be a $27^2*27^2$ matrix. We need to use both correct document and the document with typos to train this matrix. For each $e_{ij}$, we first calculate the appearance times of the jth observed state at position t in the typo document when ith hidden state is at position t in the correct document. And then we could normalize the matrix so that the sum of each row to be one.\n",
    "\n",
    "Initial State Vector: it is the initial state distribution. Entry $e_i$ reprensents the probability of the hidden state at position t being ith hidden state. The length of the vector is 27. We need to use our correct document to train this vector. For each entry $e_i$, we first calculate the appearance times of ith hidden state in the whole correct document and then normalize the vector so that the sum of the vector is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = len(correct) # length of document\n",
    "# initialize Transition and Emission Matrix, adding a small pseudocount\n",
    "T = np.full((27, 27), 10**(-10))\n",
    "E = np.full((27, 27), 10**(-10))\n",
    "# initialize Initialize state distribution vector\n",
    "I = np.zeros(27)\n",
    "\n",
    "# loop through position 1 to N-1 to update T, E and I\n",
    "for t in range(N-1):\n",
    "    # the index of the hidden state at position t\n",
    "    i = states_set.index(correct[t])\n",
    "    # the index of the hidden state at position t+1\n",
    "    j = states_set.index(correct[t+1])\n",
    "    # the index of the observed state at position t\n",
    "    k = states_set.index(typo[t])\n",
    "    # update the counts for T,E and I\n",
    "    T[i,j] += 1.\n",
    "    E[i,k] += 1.\n",
    "    I[i] += 1.\n",
    "\n",
    "# add the info of last position t=N to E and I\n",
    "E[states_set.index(correct[N-1]),states_set.index(typo[N-1])] += 1.\n",
    "I[states_set.index(correct[N-1])] += 1.\n",
    "\n",
    "# normalize our matrices so that the sum of each row =1\n",
    "T = T/np.sum(T, axis=1).reshape(27,1)\n",
    "E = E/np.sum(E, axis=1).reshape(27,1)\n",
    "I = I/np.sum(I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Implement the Viterbi algorithm and run it on a test portion that contains errors. Show that your Viterbi implementation can improve text of length 100, 500, 1000, and 2000. **\n",
    "\n",
    "Note: To do this correctly you would have to withhold the part of the text that you use for testing when you estimate the parameters for you HMM. For the sake of this homework it is ok though to report training error instead of test error. Just be aware that the correction rate you are reporting most likely is a very optimistic estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: https://en.wikipedia.org/wiki/Viterbi_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi(obs,order=1,states=states_set, I=I, T=T, E=E):\n",
    "    \n",
    "    # take log of initial state, transition, emission matrix\n",
    "    logI = np.log(I)\n",
    "    logT = np.log(T)\n",
    "    logE = np.log(E)\n",
    "    \n",
    "    N = len(obs) #length of sequence\n",
    "    S = len(states)**order #length of hidden states\n",
    "    \n",
    "    # The probability of the most likely path so far \n",
    "    T1 = np.zeros((S, N))\n",
    "    # stores x_j-1 of the most likely path so far\n",
    "    T2 = np.zeros((S, N))\n",
    "\n",
    "    T1[:,0] = logI + logE[:, states.index(obs[0])]\n",
    "\n",
    "    for i in range(1,N):\n",
    "        for j in range(S):\n",
    "            log_like = T1[:, i-1] + logT[:, j] + logE[j, states.index(obs[i])]\n",
    "            T1[j,i] = np.max(log_like)\n",
    "            T2[j,i] = np.argmax(log_like)\n",
    "\n",
    "    Z = np.zeros(N)\n",
    "    Z[N-1] = np.argmax(T1[:,N-1])\n",
    "    \n",
    "    for i in range(N-1, 0, -1):\n",
    "        Z[i-1] = T2[Z[i], i]\n",
    "    # The most likely hidden state sequence\n",
    "    if order==1:\n",
    "        X = [states[int(i)] for i in Z]\n",
    "    if order==2:\n",
    "        X = [states[int(i)%27] for i in Z]\n",
    "      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text of length 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typo:\n",
      "fron fbirest crebtuses we eesjsf iocrease uhat therfbz bebuuys rose night never eie buu as uie siper\n",
      "corrected:\n",
      "eron fairest breatuses we desise increase that thereay beautys rore might mever die but as the siper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:31: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "obs_100 = typo[0:100]\n",
    "print 'typo:'\n",
    "print obs_100\n",
    "\n",
    "result = viterbi(obs=obs_100)\n",
    "corrected_seq_100 = ''\n",
    "for i in result:\n",
    "    corrected_seq_100 += i\n",
    "    \n",
    "print 'corrected:'\n",
    "print corrected_seq_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text of length 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typo:\n",
      "fron fbirest crebtuses we eesjsf iocrease uhat therfbz bebuuys rose night never eie buu as uie siper shoumd by timf eeceasf hjt tenefr iejs might bear hjs memory but thou dontractfe to thjne pwn bsight eyfs feedsu tiy mightt flane with selgsubstanuial guel mbking a famiof where abvneance lies thy self uiy foe to thz swfeu selg top csuel thou uhat ast oow the wprlds fsesi ornbmfnu and only hframd uo the gaudy sqring wjuhin thioe pwo cue buriest tiy conuent aod tendfs dhurl nakst waste jn nighardi\n",
      "corrected:\n",
      "eron fairest breatuses we desise increase that thereay beautys rore might mever die but as the siper should by time decease hit tender heis might bear his melory but thou dontractee to thine own bright eyes feedst thy mightt flane with selfrtastanthal guel making a famine where abuneance lies thy self thy foe to thy sweet self too bstel thou that ast oow the worlds fresh ornament and only herald to the gaudy spring within thine owo bue buriest thy content and tendes churl makst waste in mighardi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:31: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "obs_500 = typo[0:500]\n",
    "print 'typo:'\n",
    "print obs_500\n",
    "\n",
    "result = viterbi(obs=obs_500)\n",
    "corrected_seq_500 = ''\n",
    "for i in result:\n",
    "    corrected_seq_500 += i\n",
    "    \n",
    "print 'corrected:'\n",
    "print corrected_seq_500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typo:\n",
      "fron fbirest crebtuses we eesjsf iocrease uhat therfbz bebuuys rose night never eie buu as uie siper shoumd by timf eeceasf hjt tenefr iejs might bear hjs memory but thou dontractfe to thjne pwn bsight eyfs feedsu tiy mightt flane with selgsubstanuial guel mbking a famiof where abvneance lies thy self uiy foe to thz swfeu selg top csuel thou uhat ast oow the wprlds fsesi ornbmfnu and only hframd uo the gaudy sqring wjuhin thioe pwo cue buriest tiy conuent aod tendfs dhurl nakst waste jn nighardiog pjtz tif worle or elsf thjs gluttpo be to fau uie xorles dve cz the grave bnd thee when fosuy wioters shamm betiege thy brow aod eih effp trendiet in uiy bfautys fiemd tiy youths proud livfsy so gazfd on now wjll be a tpttere xefd of snall wprti hele then bejnh askfd whese aml thy ceauuy ljes where all tie trfature og thy lvsuy days to say withio thine own effp tunken eyet wese ao alleauinh thame and thriftmess praise how mudh more praise eftervd thy beautys use ig thou covmdst antwer tiis ga\n",
      "corrected:\n",
      "eron fairest breatuses we desise increase that thereay beautys rore might mever die but as the siper should by time decease hit tender heis might bear his melory but thou dontractee to thine own bright eyes feedst thy mightt flane with selfrtastanthal guel making a famine where abuneance lies thy self thy foe to thy sweet self too bstel thou that ast oow the worlds fresh ornament and only herald to the gaudy spring within thine owo bue buriest thy content and tendes churl makst waste in migharding pity the worle or else this gluston be to fat the worles dve by the grave and thee when fosty winters shall bethege thy brow and dig effo trendiet in thy beautys field thy youths proud livery so gazed on now will be a tostere weed of small worth hele then being asked whese all thy beauty lies where all the treature of thy lusty days to say within thine own effo tunken eyet wese an alleating thame and thriftless praise how much more praise deserud thy beautys tse ig thou couldst antwer this ga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "obs_1000 = typo[0:1000]\n",
    "print 'typo:'\n",
    "print obs_1000\n",
    "\n",
    "result = viterbi(obs=obs_1000)\n",
    "corrected_seq_1000 = ''\n",
    "for i in result:\n",
    "    corrected_seq_1000 += i\n",
    "    \n",
    "print 'corrected:'\n",
    "print corrected_seq_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length of 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typo:\n",
      "fron fbirest crebtuses we eesjsf iocrease uhat therfbz bebuuys rose night never eie buu as uie siper shoumd by timf eeceasf hjt tenefr iejs might bear hjs memory but thou dontractfe to thjne pwn bsight eyfs feedsu tiy mightt flane with selgsubstanuial guel mbking a famiof where abvneance lies thy self uiy foe to thz swfeu selg top csuel thou uhat ast oow the wprlds fsesi ornbmfnu and only hframd uo the gaudy sqring wjuhin thioe pwo cue buriest tiy conuent aod tendfs dhurl nakst waste jn nighardiog pjtz tif worle or elsf thjs gluttpo be to fau uie xorles dve cz the grave bnd thee when fosuy wioters shamm betiege thy brow aod eih effp trendiet in uiy bfautys fiemd tiy youths proud livfsy so gazfd on now wjll be a tpttere xefd of snall wprti hele then bejnh askfd whese aml thy ceauuy ljes where all tie trfature og thy lvsuy days to say withio thine own effp tunken eyet wese ao alleauinh thame and thriftmess praise how mudh more praise eftervd thy beautys use ig thou covmdst antwer tiis gajs child of nine thamm svm ny count and nake my old fxcvse qroving his beauuy by tuccession tiine tiis xerf to ce new made when thou brt pld and sfe tiy bmood warm xhfn thou feelst iu cold lool in uhy gmass and tell the gace thou viewest oow is uhe timf uhbt facf thould forn aoother xhose frfsh repair ig npw thou not rfofwesu thou eost beguile the world uncless tomf motier for xiere is tie so fbis whose unfared xomc disdaios tie ujllbgf pf uhy hutbandry or who is hf to fond xill ce the uomb of his selflpve to suop qosterity thov art tiy nouhers glbss and she io uhee callt bbdl uhe movfly aqrim of hfr prine so tiou tirouhh xindowt of uhinf bge shalt tee despjue of wrinklft this thy gomdfn time bvt ig uhou liwe semembered not to be dje single ane tiine imahe dift wiuh uhff unthriftz lovelinfss whz dosu thpu spene upoo thy sflf thy beautys legacy nauuses bequest hives nothjnh but douh lend and being frank she mends to uhose are free then bfavteput njggbre xhy dosu tipv abute tie bounueous\n",
      "corrected:\n",
      "eron fairest breatuses we desise increase that thereay beautys rore might mever die but as the siper should by time decease hit tender heis might bear his melory but thou dontractee to thine own bright eyes feedst thy mightt flane with selfrtastanthal guel making a famine where abuneance lies thy self thy foe to thy sweet self too bstel thou that ast oow the worlds fresh ornament and only herald to the gaudy spring within thine owo bue buriest thy content and tendes churl makst waste in migharding pity the worle or else this gluston be to fat the worles dve by the grave and thee when fosty winters shall bethege thy brow and dig effo trendiet in thy beautys field thy youths proud livery so gazed on now will be a tostere weed of small worth hele then being asked whese all thy beauty lies where all the treature of thy lusty days to say within thine own effo tunken eyet wese an alleating thame and thriftless praise how much more praise deserud thy beautys tse ig thou couldst antwer this gais child of mine thall sum my count and make my old excuse proving his beauty by tuccesshon thine this were to be mew made when thou brt pld and see thy blond warm when thou feelst it cold lool in thy glass and tell the gace thou vievest oow is the time that face thould forn another whore fresh repair ig now thou not renevest thou dost beguile the world unckess tome mother for where is the so fais whore uneared womb discains the tillage pe thy hutbandry or who is he to fond will be the toma of his selflove to stoo posterity thou art thy nothers glass and she in thee callt bacl the movely aprim of her prine so thou tirough windows of thine age shalt tee despite of wrinklft this thy folden time but ig thou live semembered not to be die single ane thine image dift with thee unthrifty loveliness why dost thou spene tono thy self thy beautys lefaby matuses bequest hives nothing but doth lend and being frank she mends to thore are free then beauteput miggare why dost thou abute the bounteous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:31: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "obs_2000 = typo[0:2000]\n",
    "print 'typo:'\n",
    "print obs_2000\n",
    "\n",
    "result = viterbi(obs=obs_2000)\n",
    "corrected_seq_2000 = ''\n",
    "for i in result:\n",
    "    corrected_seq_2000 += i\n",
    "    \n",
    "print 'corrected:'\n",
    "print corrected_seq_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, it seems that my Viterbi implementation can improve text of length 100, 500, 1000, and 2000. In the next section, I will calculate the accuracy rate before and after correction to show that the text get improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What correction rate do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(obs, correct):\n",
    "    correct_count = np.sum(obs[i] == correct[i] for i in range(len(obs)))\n",
    "    return correct_count/float(len(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 100 accuracy before correction: 0.8\n",
      "length 100 accuracy after correction: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Text of length 100\n",
    "print 'length 100 accuracy before correction:', accuracy(obs_100,correct[:100])\n",
    "print 'length 100 accuracy after correction:', accuracy(corrected_seq_100,correct[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 500 accuracy before correction: 0.822\n",
      "length 500 accuracy after correction: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Text of length 500\n",
    "print 'length 500 accuracy before correction:', accuracy(obs_500,correct[:500])\n",
    "print 'length 500 accuracy after correction:', accuracy(corrected_seq_500,correct[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 1000 accuracy before correction: 0.823\n",
      "length 1000 accuracy after correction: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Text of length 1000\n",
    "print 'length 1000 accuracy before correction:', accuracy(obs_1000,correct[:1000])\n",
    "print 'length 1000 accuracy after correction:', accuracy(corrected_seq_1000,correct[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 2000 accuracy before correction: 0.8325\n",
      "length 2000 accuracy after correction: 0.9355\n"
     ]
    }
   ],
   "source": [
    "# Text of length 2000\n",
    "print 'length 2000 accuracy before correction:', accuracy(obs_2000,correct[:2000])\n",
    "print 'length 2000 accuracy after correction:', accuracy(corrected_seq_2000,correct[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that the accuracy rate of text of length 100, 500, 1000, and 2000 all get improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Seond Order HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Give an intuitive explanation why a second order HMM should give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of a HMM of fixed order, is the length of the history or context upon which the probabilities of the possible values of the next state depend. The next state of an order 2 (second-order) HMM depends upon the two previous states. Thus, the probability of transitioning to a new state depends not only on the current state, but also on the previous state. This allows a more realistic context-dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Implement your second order text correction. Hint: If you think a bit about the model you won't even have to change your Viterbi implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = len(correct) # length of document\n",
    "# initialize Transition and Emission Matrix, adding a small pseudocount\n",
    "T_2 = np.full((27**2, 27**2), 10**(-10))\n",
    "E_2 = np.full((27**2, 27), 10**(-10))\n",
    "# initialize Initialize state distribution vector\n",
    "I_2 = np.zeros(27**2)\n",
    "\n",
    "# loop through position 1 to N-1 to update T, E and I\n",
    "for t in range(1,N-1):\n",
    "    # the index of the hidden state at position t-1\n",
    "    i0 = states_set.index(correct[t-1])\n",
    "    # the index of the hidden state at position t\n",
    "    i1 = states_set.index(correct[t])\n",
    "    # the index of the hidden state at position t+1\n",
    "    i2 = states_set.index(correct[t+1])\n",
    "    # the index of the observed state at position t\n",
    "    k = states_set.index(typo[t])\n",
    "    # update the counts for T,E and I\n",
    "    T_2[i0*27+i1,i1*27+i2] += 1.\n",
    "    E_2[i0*27+i1,k] += 1.\n",
    "    I_2[i0*27+i1] += 1.\n",
    "\n",
    "# add the info of last 2 positions t=N-1,N to E and I\n",
    "i_N1 = states_set.index(correct[N-2]) # the index of the hidden state at position N-2\n",
    "i_N = states_set.index(correct[N-1]) # the index of the hidden state at position N-1\n",
    "k_N = states_set.index(typo[N-1]) # the index of the observed state at position N-1\n",
    "# update the counts for E and I\n",
    "E_2[i_N1*27+i_N,k_N] += 1.\n",
    "I_2[i_N1*27+i_N] += 1.\n",
    "\n",
    "# normalize our matrices so that the sum of each row =1\n",
    "T_2 = T_2/np.sum(T_2, axis=1).reshape(27**2,1)\n",
    "E_2 = E_2/np.sum(E_2, axis=1).reshape(27**2,1)\n",
    "I_2 = I_2/np.sum(I_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare your correction rates against the first order model for text length of 100 and 500, (you can do 1000 as well if your computer is fast enough). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o2 length 100 accuracy: 0.97\n",
      "o1 length 100 accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "result = viterbi(obs=obs_100,order=2, I=I_2, E=E_2, T=T_2)\n",
    "o2_corrected_seq_100 = ''\n",
    "for i in result:\n",
    "    o2_corrected_seq_100 += i\n",
    "# Text of length 100\n",
    "print 'o2 length 100 accuracy:', accuracy(o2_corrected_seq_100,correct[:100])\n",
    "print 'o1 length 100 accuracy:', accuracy(corrected_seq_100,correct[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length of 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o2 length 500 accuracy: 0.976\n",
      "o1 length 500 accuracy: 0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "result = viterbi(obs=obs_500,order=2, I=I_2, E=E_2, T=T_2)\n",
    "o2_corrected_seq_500 = ''\n",
    "for i in result:\n",
    "    o2_corrected_seq_500 += i\n",
    "# Text of length 500\n",
    "print 'o2 length 500 accuracy:', accuracy(o2_corrected_seq_500,correct[:500])\n",
    "print 'o1 length 500 accuracy:', accuracy(corrected_seq_500,correct[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o2 length 1000 accuracy: 0.973\n",
      "o1 length 1000 accuracy: 0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crystal/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "result = viterbi(obs=obs_1000,order=2, I=I_2, E=E_2, T=T_2)\n",
    "o2_corrected_seq_1000 = ''\n",
    "for i in result:\n",
    "    o2_corrected_seq_1000 += i\n",
    "# Text of length 1000\n",
    "print 'o2 length 1000 accuracy:', accuracy(o2_corrected_seq_1000,correct[:1000])\n",
    "print 'o1 length 1000 accuracy:', accuracy(corrected_seq_1000,correct[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we could clearly see that the accuracy score of the order 2 model get significantly improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. How well would your implementation scale to HMMs of even higher order?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of 1st and 2nd order algorithm are both O(n). However, the scale of the 2 algorithms are different. The scale of the first order algorithm is 27 and the scale of the second order algorithm is 27^2. \n",
    "\n",
    "When we get even higher order (N), the complexity of the algorithm won't change and the scale of the algorithm will be 27^N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Problem 2: Final Project Review\n",
    "    \n",
    "You will be contacted shortly by a TF to meet and discuss your final project proposal. Be sure to take advantage of this feedback option. Review meetings should be scheduled within the week from April 11-15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
